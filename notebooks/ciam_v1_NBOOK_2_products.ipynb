{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Products full data\n",
    "\n",
    "This notebook fetches the full data of each of the product we have in our products for QA.\n",
    "This notebook also corrects the invalid product_asin that is in some of the qa our synthetic products has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install --quiet python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "product_path = \"../initial-training-sets/datasets/\"\n",
    "qa_json_filenames = [\"men_fashion_qa.json\", \"skin_care_qa.json\", \"women_fashion_qa.json\"]\n",
    "\n",
    "dataset_products = {}\n",
    "for qa_json_filename in qa_json_filenames:\n",
    "    qa_product_list = json.loads(Path(product_path + qa_json_filename).read_text())\n",
    "    \n",
    "    for qa_product in qa_product_list:\n",
    "        if qa_product['category'] not in dataset_products:\n",
    "            dataset_products[qa_product['category']] = {\n",
    "                \"products\": [],\n",
    "                \"qa\": []\n",
    "            }\n",
    "\n",
    "        _qa_product = deepcopy(qa_product)\n",
    "        # del _qa_product['product_asin']\n",
    "        dataset_products[qa_product['category']]['qa'].append(_qa_product)\n",
    "        raw_products_path = Path(f\"../initial-training-sets/{qa_product['category']}/raw_products.json\")\n",
    "        # cache function? lru_cache?\n",
    "        raw_products = json.loads(Path(raw_products_path).read_text())\n",
    "        \n",
    "        matched_products = [ raw_product for raw_product in raw_products if raw_product['product_asin'] == qa_product['product_asin'] or qa_product['product_asin'] in raw_product['description'] ]\n",
    "        dataset_products[qa_product['category']]['products'].extend(matched_products)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the product_asin in the qa list\n",
    "corrected_dataset_products = {}\n",
    "for index, category in enumerate(dataset_products):\n",
    "\n",
    "    products = dataset_products[category]['products']\n",
    "    qa = dataset_products[category]['qa']\n",
    "    \n",
    "    new_qa = []\n",
    "    for qa_product in qa:\n",
    "        correct_product = [product for product in products if qa_product['product_asin'] != product['product_asin'] and qa_product['product_asin'] in product['description']]\n",
    "        if correct_product:\n",
    "            _qa_product = deepcopy(qa_product)\n",
    "            _qa_product['product_asin'] = correct_product[0]['product_asin']\n",
    "            new_qa.append(_qa_product)\n",
    "        else:\n",
    "            new_qa.append(qa_product)\n",
    "            \n",
    "    corrected_dataset_products[category]  = {\n",
    "            \"products\": products,\n",
    "            \"qa\": new_qa\n",
    "        }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOMEN_FASHION_NO_REVIEWS, MEN_FASHION_WITH_REVIEWS, SKIN_CARE_WITH_REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_dataset_products['WOMEN_FASHION_NO_REVIEWS']['products']), len(corrected_dataset_products['WOMEN_FASHION_NO_REVIEWS']['qa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_dataset_products['MEN_FASHION_WITH_REVIEWS']['products']), len(corrected_dataset_products['MEN_FASHION_WITH_REVIEWS']['qa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_dataset_products['SKIN_CARE_WITH_REVIEWS']['products']), len(corrected_dataset_products['SKIN_CARE_WITH_REVIEWS']['qa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the products to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-comment this if you do not have the corrected products \n",
    "# Path(\"../initial-training-sets/datasets/dataset_products.json\").write_text(\"\")\n",
    "# Path(\"../initial-training-sets/datasets/dataset_products.json\").write_text(json.dumps(corrected_dataset_products))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move the corresponding product images as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "dataset_images_dir_path = Path(\"../initial-training-sets/datasets/images\")\n",
    "if not dataset_images_dir_path.exists():\n",
    "    os.makedirs(dataset_images_dir_path, exist_ok=True)\n",
    "\n",
    "for title in corrected_dataset_products:\n",
    "    products = corrected_dataset_products[title]['products']\n",
    "    raw_products_path = Path(f\"../initial-training-sets/{title}/images\")\n",
    "    for product in products:\n",
    "        for image_path in [path for path in os.listdir(raw_products_path.absolute()) if product['product_asin'] in path]:\n",
    "            shutil.copy(str(raw_products_path.absolute()) +  \"/\" + image_path, str(dataset_images_dir_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
